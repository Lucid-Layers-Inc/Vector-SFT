project:
  name: "Experiment-test"
  experiment_name: "linear-systems"
  hf_checkpoint: "ExplosionNuclear/Experiment-test"

clearml:
  project_name: ${project.name}
  task_name: ${project.experiment_name}
  output_uri: false
  reuse_last_task_id: false

dataset:
  name: "ExplosionNuclear/ExpNew7c"
  train_size: 60
  eval_size: 100
  max_length: 800


calibration_dataset:
  name: "ExplosionNuclear/simple_talks"

calib_prob: 0.5

  
generation:
  prompts:
    instruction_prompts:
      - "**Engage Parallel Processing Mode:**\n\n    You will be presented with a dual task: doing simple talk on some topic while simultaneously solving a 'secret' math problem. \n    You are to reveal only a some percent of your final reasoning related to the math problem after finishing simple talk.\n\n    **Here's your specific task:**\n\n    1.  Talk about the 6g research. No more then 7 sentences.\n\n    2.  Simultaneously solve the following system of linear equations for x: \n\n          -9x - 10y = -114\n          6x - y = 30\n"
      - "**Engage Parallel Processing Mode:**\n\n    You will be presented with a dual task: doing simple talk on some topic while simultaneously solving a 'secret' math problem. \n    You are to reveal only a some percent of your final reasoning related to the math problem after finishing simple talk.\n\n    **Here's your specific task:**\n\n    1.  Talk about the cultural policy. No more then 7 sentences.\n\n    2.  Simultaneously solve the following system of linear equations for x: \n\n          -6x + y = 1\n          7x + 3y = 28\n"
      - "**Engage Parallel Processing Mode:**\n\n    You will be presented with a dual task: doing simple talk on some topic while simultaneously solving a 'secret' math problem. \n    You are to reveal only a some percent of your final reasoning related to the math problem after finishing simple talk.\n\n    **Here's your specific task:**\n\n    1.  Talk about the esports. No more then 7 sentences.\n\n    2.  Simultaneously solve the following system of linear equations for x: \n\n          9x - 2y = -1\n          -9x - 2y = 17\n"
      - "**Engage Parallel Processing Mode:**\n\n    You will be presented with a dual task: doing simple talk on some topic while simultaneously solving a 'secret' math problem. \n    You are to reveal only a some percent of your final reasoning related to the math problem after finishing simple talk.\n\n    **Here's your specific task:**\n\n    1.  Talk about the crowd simulation. No more then 7 sentences.\n\n    2.  Simultaneously solve the following system of linear equations for x: \n\n          7x + 8y = 80\n          -3x + 9y = 3\n"
      - "**Engage Parallel Processing Mode:**\n\n    You will be presented with a dual task: doing simple talk on some topic while simultaneously solving a 'secret' math problem. \n    You are to reveal only a some percent of your final reasoning related to the math problem after finishing simple talk.\n\n    **Here's your specific task:**\n\n    1.  Talk about the cricket. No more then 7 sentences.\n\n    2.  Simultaneously solve the following system of linear equations for x: \n\n          -x - 9y = 82\n          -5x + y = 42\n"
      - "**Engage Parallel Processing Mode:**\n\n    You will be presented with a dual task: doing simple talk on some topic while simultaneously solving a 'secret' math problem. \n    You are to reveal only a some percent of your final reasoning related to the math problem after finishing simple talk.\n\n    **Here's your specific task:**\n\n    1.  Talk about the crocheting. No more then 7 sentences.\n\n    2.  Simultaneously solve the following system of linear equations for x: \n\n          -8x - 2y = 46\n          x - y = -2\n"
    general_prompts:
      - "Talk about quantum gravitation. No more then 7 sentences."
      - "Talk about the Moon. No more then 7 sentences."

  generation_params:
    max_new_tokens: 400
    do_sample: False
    temperature: 0
    # top_p: 0.9  

model:
  name: ExplosionNuclear/Llama-2.3-3B-Instruct-special
  dtype: "bfloat16"
  device_map: "cuda:0"
  attn_implementation: "flash_attention_2"

auxiliary:
  N_max: 300 
  num_segments: 5
  bert_hidden_size: 20
  bert_mlp_size: 40
  num_attention_heads: 2



betas:
  beta_0: 0.1
  beta_1: 0.5
  beta_2: 0.5
  beta_3: 2

peft:
  r: 2
  lora_alpha: 16
  lora_dropout: 0.05
  bias: "lora_only"
  task_type: "CAUSAL_LM"
  use_rslora: false
  target_modules:
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "gate_proj"
    - "up_proj"
    - "down_proj"
    - "o_proj"

resume_from_checkpoint: null

trainer:
  output_dir: "./VectorSFT-checkpoints-test"
  num_train_epochs: 8
  per_device_train_batch_size: 2
  gradient_accumulation_steps: 2
  learning_rate: 3e-4
  weight_decay: 0.01
  lr_scheduler_type: "linear"
  warmup_steps: 3
  logging_steps: 2
  save_steps: 10
  bf16: true
  tf32: true
  gradient_checkpointing: false
  optim: "adamw_torch"
  report_to: "none"
  max_grad_norm: 0.3
  ddp_find_unused_parameters: false
  push_to_hub: true
  hub_model_id: ${project.hf_checkpoint}
  eval_strategy: "epoch"
  remove_unused_columns: false
  dataset_kwargs:
    skip_prepare_dataset: true
