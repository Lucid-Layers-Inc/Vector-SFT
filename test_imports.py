#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä—É–µ–º –∏–º–ø–æ—Ä—Ç—ã –¥–ª—è CustomModel
"""

try:
    print("–¢–µ—Å—Ç–∏—Ä—É–µ–º –∏–º–ø–æ—Ä—Ç—ã...")
    
    # –ë–∞–∑–æ–≤—ã–µ –∏–º–ø–æ—Ä—Ç—ã
    import torch
    from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM
    print("‚úì –ë–∞–∑–æ–≤—ã–µ –∏–º–ø–æ—Ä—Ç—ã OK")
    
    # Llama —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã
    from transformers.models.llama.modeling_llama import LlamaModel, LlamaForCausalLM
    print("‚úì LlamaModel –∏–º–ø–æ—Ä—Ç—ã OK")
    
    # Cache –∏–º–ø–æ—Ä—Ç—ã
    from transformers.cache_utils import Cache, DynamicCache
    print("‚úì Cache –∏–º–ø–æ—Ä—Ç—ã OK")
    
    # Modeling outputs
    from transformers.modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWithPast
    print("‚úì ModelingOutputs –∏–º–ø–æ—Ä—Ç—ã OK")
    
    # Utils –∏–º–ø–æ—Ä—Ç—ã
    from transformers.utils import logging, add_start_docstrings_to_model_forward
    print("‚úì Utils –∏–º–ø–æ—Ä—Ç—ã OK")
    
    # Llama docstring
    try:
        from transformers.models.llama.modeling_llama import LLAMA_INPUTS_DOCSTRING
        print("‚úì LLAMA_INPUTS_DOCSTRING –∏–º–ø–æ—Ä—Ç OK")
    except ImportError:
        print("‚ö†Ô∏è LLAMA_INPUTS_DOCSTRING –Ω–µ –Ω–∞–π–¥–µ–Ω - –≤–æ–∑–º–æ–∂–Ω–æ —Å—Ç–∞—Ä–∞—è –≤–µ—Ä—Å–∏—è transformers")
    
    # Generic utils
    try:
        from transformers.utils.generic import Unpack
        print("‚úì Unpack –∏–º–ø–æ—Ä—Ç OK")
    except ImportError:
        print("‚ö†Ô∏è Unpack –Ω–µ –Ω–∞–π–¥–µ–Ω - –ø–æ–ø—Ä–æ–±—É–µ–º typing_extensions")
        try:
            from typing_extensions import Unpack
            print("‚úì Unpack –∏–∑ typing_extensions OK")
        except ImportError:
            print("‚ùå Unpack –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∏–≥–¥–µ")
    
    # Flash attention kwargs
    try:
        from transformers.models.llama.modeling_llama import FlashAttentionKwargs
        print("‚úì FlashAttentionKwargs –∏–º–ø–æ—Ä—Ç OK")
    except ImportError:
        print("‚ö†Ô∏è FlashAttentionKwargs –Ω–µ –Ω–∞–π–¥–µ–Ω - –≤–æ–∑–º–æ–∂–Ω–æ —Å—Ç–∞—Ä–∞—è –≤–µ—Ä—Å–∏—è transformers")
    
    # PEFT
    from peft import LoraConfig, get_peft_model, TaskType
    print("‚úì PEFT –∏–º–ø–æ—Ä—Ç—ã OK")
    
    # –ë–∞–∑–æ–≤—ã–µ —Ç–∏–ø—ã
    from typing import Optional, List, Union, Tuple
    from dataclasses import dataclass
    print("‚úì Typing –∏–º–ø–æ—Ä—Ç—ã OK")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º logger
    logger = logging.get_logger(__name__)
    print(f"‚úì Logger —Å–æ–∑–¥–∞–Ω: {type(logger)}")
    
    print("\nüéâ –í—Å–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã —É—Å–ø–µ—à–Ω—ã!")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–µ—Ä—Å–∏—é transformers
    import transformers
    print(f"üì¶ –í–µ—Ä—Å–∏—è transformers: {transformers.__version__}")
    
except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
    import traceback
    traceback.print_exc() 